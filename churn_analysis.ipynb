{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ce32e86-3599-460c-856b-3567c2bca534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# General-purpose libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# Dash for web apps\n",
    "from dash import Dash, dcc, html, Input, Output\n",
    "from jupyter_dash import JupyterDash\n",
    "\n",
    "# Scikit-learn tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, VotingClassifier, VotingRegressor\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, mean_absolute_error, mean_squared_error, r2_score\n",
    ")\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, precision_recall_curve, auc\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "# Boosting models\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "\n",
    "# Statistical tools\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# SHAP for interpretability\n",
    "import shap\n",
    "\n",
    "# Joblib for saving the Models\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0fbe342-d688-4d6a-a1f7-e3d43512e9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_datasets(df, value):\n",
    "    if value == 'train':\n",
    "        df = df.merge(train_cxid, on=\"customer_id\", how=\"left\")\n",
    "    elif value == 'test':\n",
    "        df = df.merge(test_cxid, on=\"customer_id\", how=\"left\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d344655e-1689-4235-be1f-a9991f1e852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_slope(row):\n",
    "    day_cols = [f\"Day_{i}\" for i in range(1, 61)]\n",
    "    \n",
    "    try:\n",
    "        usage_values = np.array(row[day_cols].values, dtype=float)\n",
    "    except KeyError:\n",
    "        return 0  # Day columns missing\n",
    "    \n",
    "    if len(usage_values) != 60:\n",
    "        return 0\n",
    "\n",
    "    if np.isnan(usage_values).any() or np.all(usage_values == 0) or len(np.unique(usage_values)) == 1:\n",
    "        return 0  # Avoid NaNs, all-zero, or flat signals\n",
    "\n",
    "    days = np.arange(1, 61)\n",
    "    slope, _, _, _, _ = linregress(days, usage_values)\n",
    "    return slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a97e668-53ac-4156-949b-cc052706c499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "    # Day columns for feature engineering:\n",
    "    day_cols = [f\"Day_{i}\" for i in range(1, 61)]   # Observing for the first 60 days\n",
    "    usage_data = df[day_cols].astype(float).copy()\n",
    "        \n",
    "    # trend based features:\n",
    "    # 1. Exponential Moving Average (ema):\n",
    "    df[\"ema_7d\"] = usage_data.T.ewm(span=7, adjust=False).mean().T.iloc[:, -1]\n",
    "    df[\"ema_14d\"] = usage_data.T.ewm(span=14, adjust=False).mean().T.iloc[:, -1]\n",
    "    df[\"ema_30d\"] = usage_data.T.ewm(span=30, adjust=False).mean().T.iloc[:, -1]\n",
    "\n",
    "    # 2. Standard Deviation (std):\n",
    "    df[\"std_7d\"] = usage_data.iloc[:, 0:7].std(axis=1)\n",
    "    df[\"std_14d\"] = usage_data.iloc[:, 0:14].std(axis=1)\n",
    "    df[\"std_30d\"] = usage_data.iloc[:, 0:30].std(axis=1)\n",
    "\n",
    "    # behavioral features:\n",
    "    df[\"drop_trend\"] = usage_data.iloc[:, -30:].mean(axis=1) - usage_data.iloc[:, -60:-30].mean(axis=1)\n",
    "    df[\"zero_days\"] = (usage_data == 0).sum(axis=1)\n",
    "\n",
    "    # last active day:\n",
    "    last_active_series = usage_data.apply(lambda row: row[::-1].to_numpy().nonzero()[0], axis=1)\n",
    "    df[\"last_active\"] = last_active_series.apply(lambda x: 61 - x[0] if len(x) > 0 else 61)\n",
    "\n",
    "    # aggregation features:\n",
    "    df[\"total_usage\"] = usage_data.sum(axis=1)\n",
    "    df[\"average_usage\"] = usage_data.mean(axis=1)\n",
    "    df[\"max_usage\"] = usage_data.max(axis=1)\n",
    "    df[\"min_usage\"] = usage_data.min(axis=1)\n",
    "    df[\"percentile_25\"] = usage_data.quantile(0.25, axis=1)\n",
    "    df[\"percentile_75\"] = usage_data.quantile(0.75, axis=1)\n",
    "\n",
    "    # usage features:\n",
    "    df[\"usage_cv\"] = usage_data.std(axis=1) / (usage_data.mean(axis=1) + 1e-3)\n",
    "    df[\"usage_slope\"] = df.apply(compute_slope, axis=1)\n",
    "    df[\"usage_variance\"] = usage_data.var(axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a2a4091-c912-4b02-8677-6fed82ce8187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_expected_tenure(df):\n",
    "    day_cols = [f\"Day_{i}\" for i in range(1, 91)]\n",
    "    def expected_tenure(row):\n",
    "        usage = row[day_cols].values\n",
    "        non_zero = np.where(usage > 0)[0]\n",
    "        return non_zero[-1] + 1 if len(non_zero) > 0 else 0\n",
    "    df[\"expected_tenure\"] = df.apply(expected_tenure, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a82505ba-9ea1-4c98-b03d-bfad05d50519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    # Dropping customer_id due to no further use:\n",
    "    if \"customer_id\" in df.columns:\n",
    "        df.drop(columns=[\"customer_id\"], inplace=True)\n",
    "\n",
    "    # Filling Null values dynamically based on data type:\n",
    "    if df.isnull().sum().sum() > 0:\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype in ['float64', 'int64', 'int32']:\n",
    "                df[col].fillna(df[col].median(), inplace=True)\n",
    "            elif df[col].dtype == 'object':\n",
    "                df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "    # Dropping the day1-90 columns\n",
    "    day_cols = [f\"Day_{i}\" for i in range(1,91)]\n",
    "    df.drop(columns=[col for col in day_cols if col in df.columns], inplace=True)\n",
    "\n",
    "    # Rare label handling in usage_type:\n",
    "    if \"usage_type\" in df.columns:\n",
    "        rare_threshold = 0.01\n",
    "        usage_counts = df[\"usage_type\"].value_counts(normalize=True)\n",
    "        rare_usages = usage_counts[usage_counts < rare_threshold].index\n",
    "        df[\"usage_type\"] = df[\"usage_type\"].apply(lambda x: \"other\" if x in rare_usages else x)\n",
    "\n",
    "        # One-hot encode usage_type\n",
    "        df = pd.get_dummies(df, columns=[\"usage_type\"], drop_first=True)\n",
    "\n",
    "    # Convert boolean columns to integer/numerical type:\n",
    "    for col in df.select_dtypes(include=\"bool\").columns:\n",
    "        df[col] = df[col].astype(int)\n",
    "\n",
    "    # Converting object type columns to numerical columns:\n",
    "    obj_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    df[obj_cols] = df[obj_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    \n",
    "    # If this creates NaN values with median\n",
    "    df[obj_cols] = df[obj_cols].fillna(df[obj_cols].median())\n",
    "    \n",
    "    # Listing all the numerical columns of df:\n",
    "    exclude_cols = [\"churn\", \"expected_tenure\"]\n",
    "    numerical_cols = [col for col in df.select_dtypes(include=[\"float64\", \"int64\", \"int32\"]).columns\n",
    "                      if col not in exclude_cols and df[col].nunique() > 10]\n",
    "    \n",
    "    # Applying Standard Scaler to the numerical columns:\n",
    "    scaler = StandardScaler()\n",
    "    df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "    print(f\"Columns scaled: {len(numerical_cols)}\")\n",
    "    print(f\"Remaining nulls: {df.isnull().sum().sum()}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1424de39-e5b4-4525-a117-13c6d41712e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_expected_tenure(df, target=\"expected_tenure\"):\n",
    "    # Ensure no leakage from churn:\n",
    "    X = df.drop(columns=[target, \"churn\", \"last_active\"])  \n",
    "    y = df[target]\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Define models\n",
    "    models = {\n",
    "        \"Ridge\": Ridge(alpha=1.0),  # Better than plain LinearRegression for multicollinearity\n",
    "        \"RandomForest\": RandomForestRegressor(\n",
    "            n_estimators=200,\n",
    "            max_depth=15,\n",
    "            min_samples_split=5,\n",
    "            min_samples_leaf=2,\n",
    "            max_features='sqrt',\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        \"XGBoost\": XGBRegressor(\n",
    "            n_estimators=200,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            gamma=0.1,\n",
    "            reg_alpha=0.5,\n",
    "            reg_lambda=1.0,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        \"LightGBM\": LGBMRegressor(\n",
    "            n_estimators=200,\n",
    "            learning_rate=0.05,\n",
    "            num_leaves=31,\n",
    "            max_depth=-1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            reg_alpha=0.1,\n",
    "            reg_lambda=1.0,\n",
    "            random_state=42\n",
    "        ),\n",
    "        \"CatBoost\": CatBoostRegressor(\n",
    "            iterations=200,\n",
    "            learning_rate=0.05,\n",
    "            depth=6,\n",
    "            l2_leaf_reg=3,\n",
    "            subsample=0.8,\n",
    "            verbose=0,\n",
    "            random_state=42\n",
    "        )\n",
    "    }\n",
    "    results = {}\n",
    "    mae_scores = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        results[name] = {\n",
    "            \"mae\": mae,\n",
    "            \"r2\": r2,\n",
    "            \"model\": model\n",
    "        }\n",
    "\n",
    "        mae_scores.append((name, mae))\n",
    "\n",
    "    # Get top 3 models by MAE\n",
    "    top_models = sorted(mae_scores, key=lambda x: x[1])[:3]\n",
    "    voting_estimators = [(name, results[name][\"model\"]) for name, _ in top_models]\n",
    "\n",
    "    ensemble_model = VotingRegressor(estimators=voting_estimators)\n",
    "    ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate ensemble\n",
    "    y_pred_ens = ensemble_model.predict(X_test)\n",
    "    mae_ens = mean_absolute_error(y_test, y_pred_ens)\n",
    "    r2_ens = r2_score(y_test, y_pred_ens)\n",
    "\n",
    "    results[\"VotingEnsemble\"] = {\n",
    "        \"mae\": mae_ens,\n",
    "        \"r2\": r2_ens,\n",
    "        \"model\": ensemble_model\n",
    "    }\n",
    "\n",
    "    # Predict on entire dataset using best model\n",
    "    best_model_name = top_models[0][0]\n",
    "    best_model = results[best_model_name][\"model\"]\n",
    "    df[\"expected_tenure_pred\"] = best_model.predict(X)\n",
    "\n",
    "    # Compile results into a DataFrame\n",
    "    result_df = pd.DataFrame([\n",
    "        {\"Model\": k, \"MAE\": v[\"mae\"], \"R2\": v[\"r2\"]} for k, v in results.items()\n",
    "    ]).sort_values(by=\"MAE\")\n",
    "\n",
    "    return result_df, best_model, mae_ens, r2_ens, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ed8db16-91ba-4db5-a257-2237764f69fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_churn_model(df, target=\"churn\"):\n",
    "    # Drop leakage-prone columns\n",
    "    excluded_features = [target, \"expected_tenure\", \"expected_tenure_pred\", \"last_active\"]\n",
    "    X = df.drop(columns=[col for col in excluded_features if col in df.columns])\n",
    "    y = df[target]\n",
    "\n",
    "    # Encode target if it's object type\n",
    "    if y.dtype == \"object\":\n",
    "        y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "    # Stratified train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    # Define classifiers with tuned hyperparameters\n",
    "    models = {\n",
    "        \"LogisticRegression\": LogisticRegression(\n",
    "            solver=\"liblinear\",\n",
    "            max_iter=1000,\n",
    "            class_weight=\"balanced\"\n",
    "        ),\n",
    "        \"RandomForest\": RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=15,\n",
    "            min_samples_split=5,\n",
    "            min_samples_leaf=2,\n",
    "            max_features='sqrt',\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        \"XGBoost\": XGBClassifier(\n",
    "            use_label_encoder=False,\n",
    "            eval_metric=\"logloss\",\n",
    "            n_estimators=200,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            gamma=0.1,\n",
    "            reg_alpha=0.5,\n",
    "            reg_lambda=1.0,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        \"LightGBM\": LGBMClassifier(\n",
    "            n_estimators=200,\n",
    "            learning_rate=0.05,\n",
    "            num_leaves=31,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            reg_alpha=0.1,\n",
    "            reg_lambda=1.0,\n",
    "            random_state=42\n",
    "        ),\n",
    "        \"CatBoost\": CatBoostClassifier(\n",
    "            iterations=200,\n",
    "            learning_rate=0.05,\n",
    "            depth=6,\n",
    "            l2_leaf_reg=3,\n",
    "            subsample=0.8,\n",
    "            verbose=0,\n",
    "            random_state=42\n",
    "        )\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    f1_scores = []\n",
    "\n",
    "    # Train all models and evaluate\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred)\n",
    "        rec = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        results[name] = {\n",
    "            \"accuracy\": acc,\n",
    "            \"precision\": prec,\n",
    "            \"recall\": rec,\n",
    "            \"f1_score\": f1,\n",
    "            \"model\": model\n",
    "        }\n",
    "\n",
    "        f1_scores.append((name, f1))\n",
    "\n",
    "    # Build soft voting ensemble from top 3 by F1\n",
    "    top_models = sorted(f1_scores, key=lambda x: x[1], reverse=True)[:3]\n",
    "    voting_estimators = [(name, results[name][\"model\"]) for name, _ in top_models]\n",
    "\n",
    "    ensemble_model = VotingClassifier(estimators=voting_estimators, voting='soft')\n",
    "    ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_ens = ensemble_model.predict(X_test)\n",
    "    results[\"VotingEnsemble\"] = {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred_ens),\n",
    "        \"precision\": precision_score(y_test, y_pred_ens),\n",
    "        \"recall\": recall_score(y_test, y_pred_ens),\n",
    "        \"f1_score\": f1_score(y_test, y_pred_ens),\n",
    "        \"model\": ensemble_model\n",
    "    }\n",
    "\n",
    "    # Get best model by F1 score\n",
    "    best_model_name, best_f1 = sorted(f1_scores, key=lambda x: x[1], reverse=True)[0]\n",
    "    best_churn_model = results[best_model_name][\"model\"]\n",
    "\n",
    "    # Format all results into a dataframe\n",
    "    result_df = pd.DataFrame([\n",
    "        {\"Model\": k, **v} for k, v in results.items()\n",
    "    ]).drop(columns=[\"model\"]).sort_values(by=\"f1_score\", ascending=False)\n",
    "\n",
    "    # Plot ROC Curve for VotingEnsemble\n",
    "    if hasattr(ensemble_model, \"predict_proba\"):\n",
    "        y_prob_ens = ensemble_model.predict_proba(X_test)[:, 1]\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_prob_ens)\n",
    "        auc_score = roc_auc_score(y_test, y_prob_ens)\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, label=f\"Voting Ensemble (AUC = {auc_score:.3f})\", linewidth=2)\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "        plt.title(\"ROC Curve - Voting Ensemble\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return result_df, best_churn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eb7acd4-2ede-4a03-9ae5-7d9aba793c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"main.csv\")\n",
    "train_cxid = pd.read_csv(\"train_cxid.csv\")\n",
    "test_cxid = pd.read_csv(\"test_cxid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff5b1e35-9056-4a0e-b1af-f4750ef0ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = train_cxid[\"customer_id\"].unique()\n",
    "test_ids = test_cxid[\"customer_id\"].unique()\n",
    "\n",
    "df_train = df[df[\"customer_id\"].isin(train_ids)].copy()\n",
    "df_test = df[df[\"customer_id\"].isin(test_ids)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c53e6b73-154c-48fb-bfaa-c5e64822351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = merge_datasets(df_train, \"train\")\n",
    "df_test = merge_datasets(df_test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dd21bf-9f5f-478f-a403-be07b597356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = engineer_features(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799830c2-3ec2-4579-84d8-53fd17e5cb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = add_expected_tenure(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aa6ff5-0ed8-41b5-b66d-dbeac1dc0be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = preprocess_data(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596983e1-fa44-4b05-863a-35c9290253be",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_1, tenure_model, mae, r2, df_train = predict_expected_tenure(df_train, target=\"expected_tenure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087777bc-f253-4e5d-8326-7f853fff04de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47645024-ddac-4b95-9050-5c355f2c5862",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_2, best_model = train_churn_model(df_train, target=\"churn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3683e0-4fd0-4df4-882b-20f396ce553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2700aa05-4b55-4c79-8abf-a2782520f513",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = engineer_features(df_test)\n",
    "df_test = add_expected_tenure(df_test)\n",
    "df_test = preprocess_data(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96350755-1122-4352-9874-fef01483986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the expected_tenure prediction model you trained earlier\n",
    "df_test[\"expected_tenure_pred\"] = tenure_model.predict(df_test.drop(columns=[\"expected_tenure\", \"churn\", \"last_active\"], errors=\"ignore\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba04bba3-ae68-4637-bf6b-ef4bc75de227",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = df_test[\"expected_tenure\"]\n",
    "y_pred = df_test[\"expected_tenure_pred\"]\n",
    "\n",
    "# Metrics\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"RÂ²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2ec25b-111c-4762-b287-8adcbec0c896",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_cols = [\"churn\", \"expected_tenure\", \"expected_tenure_pred\", \"last_active\"]\n",
    "X_test_final = df_test.drop(columns=[col for col in exclude_cols if col in df_test.columns])\n",
    "y_test_final = df_test[\"churn\"]\n",
    "\n",
    "y_pred = best_model.predict(X_test_final)\n",
    "y_proba = best_model.predict_proba(X_test_final)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1599769-b555-4a73-9b89-821ac5f5c374",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_final, y_pred))\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test_final, y_proba)\n",
    "auc_score = roc_auc_score(y_test_final, y_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {auc_score:.3f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.title(\"ROC Curve - Churn Prediction (df_test)\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test_final, y_proba)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(recall, precision, label=f\"AUC = {pr_auc:.3f}\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91ea9ca-f38b-49fd-b73b-1ed3243240f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_churn_distribution(df_train, df_test):\n",
    "    print(\"ðŸ”¹ Churn Distribution:\")\n",
    "    print(\"Train Set:\")\n",
    "    print(df_train[\"churn\"].value_counts(normalize=True), \"\\n\")\n",
    "    \n",
    "    print(\"Test Set:\")\n",
    "    print(df_test[\"churn\"].value_counts(normalize=True))\n",
    "    \n",
    "def compare_feature_means(df_train, df_test, important_features):\n",
    "    train_means = df_train[important_features].mean()\n",
    "    test_means = df_test[important_features].mean()\n",
    "    \n",
    "    mean_diff = pd.DataFrame({\n",
    "        \"Train Mean\": train_means,\n",
    "        \"Test Mean\": test_means,\n",
    "        \"Difference\": train_means - test_means\n",
    "    })\n",
    "    return mean_diff\n",
    "\n",
    "def plot_feature_distributions(df_train, df_test, features):\n",
    "    for feature in features:\n",
    "        plt.figure(figsize=(7, 4))\n",
    "        sns.kdeplot(df_train[feature], label=\"Train\", fill=True)\n",
    "        sns.kdeplot(df_test[feature], label=\"Test\", fill=True)\n",
    "        plt.title(f\"Distribution of '{feature}'\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c6722d-a512-4917-9c48-85d82c404cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = [\n",
    "     \"expected_tenure_pred\",\"drop_trend\", \"ema_30d\",\n",
    "    \"zero_days\", \"total_usage\", \"usage_cv\"\n",
    "]\n",
    "\n",
    "compare_churn_distribution(df_train, df_test)\n",
    "\n",
    "mean_diff_df = compare_feature_means(df_train, df_test, important_features)\n",
    "print(\"\\nFeature Mean Differences:\\n\")\n",
    "print(mean_diff_df)\n",
    "\n",
    "plot_feature_distributions(df_train, df_test, important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f963f0f-5dcd-4ca8-b543-cb11b461ff9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving both the Churn Prediction Model and Expected Tenure Prediction Model using JobLib:\n",
    "\n",
    "joblib.dump(tenure_model, \"expected_tenure_model.pkl\")\n",
    "joblib.dump(best_model, \"churn_prediction_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f723a14-b6af-4c90-84ff-a48a12f7786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model, X, top_n=20):\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        importances = model.feature_importances_\n",
    "        feature_names = X.columns\n",
    "        indices = np.argsort(importances)[::-1][:top_n]\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.title(\"Top Feature Importances\", fontsize=16)\n",
    "        plt.barh(range(top_n), importances[indices][::-1], align=\"center\")\n",
    "        plt.yticks(range(top_n), [feature_names[i] for i in indices][::-1])\n",
    "        plt.xlabel(\"Relative Importance\")\n",
    "        plt.tight_layout()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"This model does not support feature_importances_ attribute.\")\n",
    "\n",
    "# Example usage:\n",
    "# plot_feature_importance(best_model, X_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81600fde-0bc4-48d6-9d7b-5da8ac0fc5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(best_model, X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87bd2fa-597c-4120-851f-6db2bcfb97e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(X_test_final.corr(), cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776b60ba-884f-49fb-af86-c282b8bdc605",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=y_test_final)\n",
    "plt.title(\"Churn Distribution in Training Data\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61871c47-e801-4cbb-83c2-29d2401537f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test_final, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e935a70-89ba-46b3-a33e-54d211657e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lift Chart (Cumulative Gain):\n",
    "\n",
    "lift_df = pd.DataFrame({'y_true': y_test_final, 'y_prob': y_proba})\n",
    "lift_df = lift_df.sort_values(by='y_prob', ascending=False)\n",
    "lift_df['cumulative_gain'] = lift_df['y_true'].cumsum() / lift_df['y_true'].sum()\n",
    "lift_df['percentage'] = np.arange(1, len(lift_df)+1) / len(lift_df)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(lift_df['percentage'], lift_df['cumulative_gain'], label='Model')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Random')\n",
    "plt.xlabel(\"Percentage of Sample\")\n",
    "plt.ylabel(\"Cumulative Gain\")\n",
    "plt.title(\"Lift (Cumulative Gain) Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2725b302-b845-46b3-a397-96441a6966f8",
   "metadata": {},
   "source": [
    "The lift chart shows that the top 40% of users ranked by predicted churn probability account for over 90% of all churners, proving the modelâ€™s value for retention targeting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494471a2-63d3-4a63-8a5b-3295192043b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gain Chart:\n",
    "\n",
    "def plot_gain_chart(y_true, y_proba):\n",
    "    df = pd.DataFrame({\"y_true\": y_true, \"y_proba\": y_proba})\n",
    "    df = df.sort_values(\"y_proba\", ascending=False).reset_index(drop=True)\n",
    "    df[\"cumulative_churn\"] = df[\"y_true\"].cumsum()\n",
    "    df[\"gain\"] = df[\"cumulative_churn\"] / df[\"y_true\"].sum()\n",
    "    df[\"percentage\"] = (df.index + 1) / len(df)\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.plot(df[\"percentage\"], df[\"gain\"], label=\"Model\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Random\")\n",
    "    plt.title(\"Gain Chart\")\n",
    "    plt.xlabel(\"Percentage of Sample\")\n",
    "    plt.ylabel(\"Cumulative Gain\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_gain_chart(y_test_final, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2831ddc8-a2f2-497e-a0a7-e48bdcc3772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration Curve:\n",
    "\n",
    "def plot_calibration_curve(y_true, y_proba, n_bins=10):\n",
    "    prob_true, prob_pred = calibration_curve(y_true, y_proba, n_bins=n_bins, strategy='quantile')\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.plot(prob_pred, prob_true, marker='o', label=\"Model\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Perfectly Calibrated\")\n",
    "    plt.title(\"Calibration Curve\")\n",
    "    plt.xlabel(\"Mean Predicted Probability\")\n",
    "    plt.ylabel(\"Fraction of Positives\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_calibration_curve(y_test_final, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bfc33b-60cd-4063-a0f8-c77963d4c248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decile-Wise Lift Table:\n",
    "\n",
    "def decile_lift_table(y_true, y_proba):\n",
    "    df = pd.DataFrame({\"y_true\": y_true, \"y_proba\": y_proba})\n",
    "    df[\"decile\"] = pd.qcut(df[\"y_proba\"], 10, labels=False)\n",
    "    lift_table = df.groupby(\"decile\").agg(\n",
    "        total_customers=(\"y_true\", \"count\"),\n",
    "        churners=(\"y_true\", \"sum\"),\n",
    "    ).sort_index(ascending=False)\n",
    "    lift_table[\"churn_rate\"] = lift_table[\"churners\"] / lift_table[\"total_customers\"]\n",
    "    lift_table[\"lift\"] = lift_table[\"churn_rate\"] / (df[\"y_true\"].sum() / len(df))\n",
    "    return lift_table\n",
    "\n",
    "display(lift_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afd6f1f-9b64-42cd-a3eb-159a058e040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohort Analysis:\n",
    "\n",
    "df = df_test.copy()\n",
    "\n",
    "# Create Expected Tenure Group\n",
    "df['tenure_group'] = pd.cut(df['expected_tenure_pred'], bins=[0, 30, 60, 90, 120],\n",
    "                            labels=['<30d', '30â€“60d', '60â€“90d', '90â€“120d'])\n",
    "\n",
    "# Create Total Usage Quartile Group\n",
    "df['usage_group'] = pd.qcut(df['total_usage'], q=4, labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "# Plot: Churn Rate by Tenure Group\n",
    "plt.figure(figsize=(6, 4))\n",
    "df.groupby('tenure_group')['churn'].mean().plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "plt.title('Churn Rate by Expected Tenure Group')\n",
    "plt.ylabel('Churn Rate')\n",
    "plt.xlabel('Tenure Group')\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot: Churn Rate by Usage Group\n",
    "plt.figure(figsize=(6, 4))\n",
    "df.groupby('usage_group')['churn'].mean().plot(kind='bar', color='salmon', edgecolor='black')\n",
    "plt.title('Churn Rate by Usage Group')\n",
    "plt.ylabel('Churn Rate')\n",
    "plt.xlabel('Usage Group')\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Pivot table: Churn rate across cohorts\n",
    "cohort_pivot = df.pivot_table(values='churn',\n",
    "                               index='tenure_group',\n",
    "                               columns='usage_group',\n",
    "                               aggfunc='mean')\n",
    "\n",
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cohort_pivot, annot=True, cmap='YlGnBu', fmt=\".2f\", cbar_kws={'label': 'Churn Rate'})\n",
    "plt.title('Cohort Churn Rate Heatmap (Tenure vs Usage)')\n",
    "plt.ylabel('Expected Tenure Group')\n",
    "plt.xlabel('Usage Level Group')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facbe124-2330-420b-b5c9-f17d50dedf30",
   "metadata": {},
   "source": [
    "**1. Tenure-Based Churn Behavior**\n",
    "\n",
    "Users with expected tenure <30 days or 30â€“60 days have the highest churn rate (~57â€“58%).\n",
    "\n",
    "Churn drastically drops for users with tenure 60â€“90 days, and is almost negligible beyond 90 days.\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "Early-stage retention is critical. If a user survives beyond 60 days, they are much more likely to stay. Your retention strategies should focus on Day 0â€“60 users.\n",
    "\n",
    "**2. Usage-Based Churn Behavior**\n",
    "\n",
    "Churn rate is highest among low-usage users (~40%).\n",
    "\n",
    "As usage increases, churn drops sharply, especially for Very High usage users (~10%).\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "Usage frequency is a strong predictor of loyalty. Encourage consistent platform engagement to reduce churn. Consider gamification, usage nudges, or incentives for low-engagement users.\n",
    "\n",
    "**3. Cohort Interaction: Tenure vs Usage Heatmap**\n",
    "\n",
    "Users with <30 days tenure & high usage still churn heavily (~72%) â†’ Red flag cohort.\n",
    "\n",
    "Users with low tenure but medium/high usage show slightly better churn, but still risky (~60%+).\n",
    "\n",
    "Users with 60â€“90 days tenure + high usage show lowest churn across the board (~9â€“18%).\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "Merely increasing usage isn't enough for new users â€” they need value delivery + onboarding support. However, medium-long-term users with high usage are your gold mine â€” build loyalty programs here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8839b5-f588-44e1-b973-b54025411798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose top features or specific feature names to visualize\n",
    "features_to_plot = [\"total_usage\", \"usage_slope\", \"drop_trend\"]  # example\n",
    "\n",
    "# Create PDP\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "PartialDependenceDisplay.from_estimator(best_model, X_test_final, features_to_plot, ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d38ec0a-1a0a-446a-9738-a8743871f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top correlated features from df_test\n",
    "top_features = [\"expected_tenure_pred\", \"drop_trend\", \"usage_cv\", \"zero_days\", \"total_usage\", \"ema_30d\"]\n",
    "corr_matrix = df_test[top_features].corr()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix of Top Predictive Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94c86a8-56eb-4e52-a9c5-3c9e8a13714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create retention categories\n",
    "df_train['retention_bucket'] = pd.cut(\n",
    "    df_train['expected_tenure_pred'], bins=[0, 30, 60, 90, 120], \n",
    "    labels=[\"<30\", \"30-60\", \"60-90\", \"90-120\"]\n",
    ")\n",
    "\n",
    "# Group and calculate churn rate per retention bucket\n",
    "retention_matrix = df_train.groupby(['retention_bucket', 'churn']).size().unstack().fillna(0)\n",
    "retention_rate = retention_matrix.div(retention_matrix.sum(axis=1), axis=0)\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.heatmap(retention_rate, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Retention vs Churn Rate Heatmap\")\n",
    "plt.xlabel(\"Churned\")\n",
    "plt.ylabel(\"Expected Tenure Group\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c0099f-4ffb-421d-864b-c6c0f8195687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top features to compare\n",
    "features_to_plot = [\"expected_tenure_pred\", \"total_usage\", \"zero_days\"]\n",
    "\n",
    "for feature in features_to_plot:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.boxplot(data=df_train, x=\"churn\", y=feature)\n",
    "    plt.title(f\"{feature} Distribution by Churn\")\n",
    "    plt.xlabel(\"Churn (0 = No, 1 = Yes)\")\n",
    "    plt.ylabel(feature)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132876a2-9208-4400-bcfd-40d50e09b0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If 'churn' is encoded as 0 (no churn) and 1 (churn):\n",
    "churn_percentage = df_train[\"churn\"].mean() * 100\n",
    "print(f\"Churn Rate: {churn_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75d6c9c-d7bd-48c5-9cae-c89cca3b627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict churn on your test data\n",
    "y_pred = best_model.predict(X_test_final)\n",
    "\n",
    "# Calculate churn percentage in predictions\n",
    "predicted_churn_percentage = np.mean(y_pred) * 100\n",
    "print(f\"Predicted Churn Rate on Test Data: {predicted_churn_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4119738b-0a8f-4db6-be26-4b897f9f5531",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_churn_percentage = y_test_final.mean() * 100\n",
    "print(f\"Actual Churn Rate in Test Set: {actual_churn_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a70da2-0ea8-4174-9f1e-b7ad52d71b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Actual Churn:     {y_test_final.mean() * 100:.2f}%\")\n",
    "print(f\"Predicted Churn:  {np.mean(y_pred) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65abf64-660e-41fd-9716-ee1f6ed0af9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar([\"Actual Churn\", \"Predicted Churn\"], [y_test_final.mean()*100, np.mean(y_pred)*100], color=[\"skyblue\", \"salmon\"])\n",
    "plt.ylabel(\"Churn Percentage (%)\")\n",
    "plt.title(\"Actual vs Predicted Churn Rate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fb2ae7-ceb5-4f1e-98e3-65fe51c5c27e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fe3129-cc0d-4e72-9a11-b8d5b0de156c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f0ee8d-2b6d-4402-9674-b76b8545032a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d5b1c4-b4e2-4f6f-b688-791d63a5f96b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031069df-366d-4017-93cb-f80a17e6e68e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e2dc08-1b2a-4791-9655-b1817f87699a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
